# =============================================================================
# AI Provider API Keys (Choose ONE)
# =============================================================================

# Google Gemini (Recommended - Fast and Free)
GEMINI_API_KEY=your_gemini_api_key_here
# Default Model: gemini-2.0-flash-exp
# Other Options: gemini-1.5-flash, gemini-1.5-pro, gemini-1.5-flash-8b

# OpenAI
# OPENAI_API_KEY=your_openai_api_key_here
# Default Model: gpt-4o-mini
# Other Options: gpt-4o, gpt-4-turbo, gpt-3.5-turbo

# Anthropic Claude
# CLAUDE_API_KEY=your_claude_api_key_here
# Default Model: claude-3-5-sonnet-20241022
# Other Options: claude-3-5-haiku-20241022, claude-3-opus-20240229

# DeepSeek
# DEEPSEEK_API_KEY=your_deepseek_api_key_here
# Default Model: deepseek-chat
# Other Options: deepseek-coder

# Grok (X.AI)
# GROK_API_KEY=your_grok_api_key_here
# Default Model: grok-beta
# Other Options: grok-2-1212, grok-2-vision-1212

# Groq (Fast Inference)
# GROQ_API_KEY=your_groq_api_key_here
# Default Model: llama-3.3-70b-versatile
# Other Options: llama-3.1-70b-versatile, mixtral-8x7b-32768

# =============================================================================
# Test Application Credentials
# =============================================================================
TEST_USERNAME=standard_user
TEST_PASSWORD=secret_sauce

# =============================================================================
# AutoHeal Configuration (Optional - Defaults shown)
# =============================================================================

# AI Provider to use (default: gemini)
# Options: gemini, openai, claude, deepseek, grok, groq
# AUTOHEAL_AI_PROVIDER=gemini

# AI Model to use (optional - uses provider's default if not specified)
# Examples:
#   For Gemini: gemini-2.0-flash-exp, gemini-1.5-flash, gemini-1.5-pro
#   For OpenAI: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
#   For Claude: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
#   For DeepSeek: deepseek-chat, deepseek-coder
#   For Grok: grok-beta, grok-2-1212, grok-2-vision-1212
#   For Groq: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
# AUTOHEAL_AI_MODEL=

# Execution Strategy (default: SMART_SEQUENTIAL)
# Options: SMART_SEQUENTIAL, DOM_ONLY, VISUAL_FIRST, PARALLEL
# AUTOHEAL_EXECUTION_STRATEGY=SMART_SEQUENTIAL

# Cache Type (default: PERSISTENT_FILE)
# Options: PERSISTENT_FILE, IN_MEMORY, NONE
# AUTOHEAL_CACHE_TYPE=PERSISTENT_FILE

# Cache Directory (default: ./autoheal-cache)
# AUTOHEAL_CACHE_DIR=./autoheal-cache

# Cache Max Size (default: 10000)
# AUTOHEAL_CACHE_MAX_SIZE=10000

# Cache TTL in hours (default: 24)
# AUTOHEAL_CACHE_TTL_HOURS=24

# Enable AI Visual Analysis (default: true)
# AUTOHEAL_VISUAL_ANALYSIS_ENABLED=true

# Element Timeout in milliseconds (default: 30000)
# AUTOHEAL_ELEMENT_TIMEOUT_MS=30000

# AI Request Timeout in milliseconds (default: 30000)
# AUTOHEAL_AI_TIMEOUT_MS=30000

# Max Retry Attempts (default: 3)
# AUTOHEAL_MAX_RETRIES=3

# Enable Reporting (default: true)
# AUTOHEAL_REPORTING_ENABLED=true

# Reports Output Directory (default: ./autoheal-reports)
# AUTOHEAL_REPORTS_DIR=./autoheal-reports

# Enable Debug Logs (default: false)
# AUTOHEAL_DEBUG_LOGS=false